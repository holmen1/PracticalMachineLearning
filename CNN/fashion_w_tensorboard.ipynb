{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bara localhost:6006 Error om https!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
